{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image  \n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del dataset\n",
    "\n",
    "Se reemplaza el atributo \"Data of birth\" por \"Age\", encodeamos \"Social Class\". También encodeamos \"Presence of Children\" para que tome 2 valores: 0 si no hay hijos, 1 en caso contrario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsv():\n",
    "    df = pd.read_csv(\"FullData2.csv\")\n",
    "    \n",
    "    #Agregamos atributo edad\n",
    "    df['Date of birth'] = pd.to_datetime('today').year - pd.to_datetime(df['Date of birth'],format='%Y-%m-%d').dt.year\n",
    "    df = df.rename(columns={'Date of birth': 'Age' })\n",
    "    \n",
    "    #Encode social class\n",
    "    socialClassEncoder = preprocessing.LabelEncoder()\n",
    "    socialClassEncoder.fit([\"AB\", \"C1\", \"C2\", \"D \", \"E \"])\n",
    "    \n",
    "    df['Social Class'] = socialClassEncoder.transform(df['Social Class'])\n",
    "    \n",
    "    #Agrupamos en 2 clases \"Presence of Children\"\n",
    "    df['Presence of Children'] = df['Presence of Children'].apply(lambda x: 1 if x > 1 else 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = readCsv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Partición de datos \n",
    "\n",
    "Particionamos el conjunto entre datos de entramiento y de test. Los de validación se van a ir generando en cada uno de los k-folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def partitionate(df):\n",
    "    #Seteamos Presence of Children como target\n",
    "    targetColumn = \"Presence of Children\"\n",
    "    \n",
    "    #El resto de las columnas las vamos a usar como feature para clasificar\n",
    "    features = list(df.columns)\n",
    "    features.remove(targetColumn)\n",
    "    \n",
    "    #Eliminamos otras columnas que están muy relacionadas con lo que queremos predecir (deberíamos sacarlas del csv)\n",
    "    features.remove(\"Demographic cell 1\")\n",
    "    features.remove(\"Mosaic Classification\")\n",
    "    features.remove(\"Life stage\")\n",
    "    features.remove(\"No of People\")\n",
    "    features.remove(\"Age\")\n",
    "    features.remove(\"Terminal age of education\")\n",
    "\n",
    "    return train_test_split(df[features], df[targetColumn], train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "X, test_X, y, test_y = partitionate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Árboles de decisión \n",
    "\n",
    "Entrenar un árbol de decisión con altura 3 y el resto de los hiperparámetros con su valor en default. Estimar la performance del modelo utilizando 5-fold cross validation utilizando el Accuracy y ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Conjunto de validación\n",
      "Values:  [0.794, 0.799, 0.806, 0.804, 0.786]  Promedio =  0.798  Desvio =  0.007 \n",
      "\n",
      "Accuracy: Conjunto de entrenamiento\n",
      "Values:  [0.801, 0.8, 0.796, 0.797, 0.803]  Promedio =  0.799  Desvio =  0.003 \n",
      "\n",
      "ROC AUC: Conjunto de validación\n",
      "Values:  [0.754, 0.755, 0.761, 0.758, 0.749]  Promedio =  0.755  Desvio =  0.004 \n",
      "\n",
      "ROC AUC: Conjunto de entrenamiento\n",
      "Values:  [0.76, 0.76, 0.752, 0.755, 0.761]  Promedio =  0.758  Desvio =  0.003 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def kfold(max_depth = 3, criterion = \"gini\", round_decimals = 3):\n",
    "    kf = KFold(n_splits = 5)\n",
    "    \n",
    "    accuracyValidation = []\n",
    "    accuracyTrain = []\n",
    "    rocAucValidation = []\n",
    "    rocAucTrain = []\n",
    "    \n",
    "    for train_index, validation_index in kf.split(X):\n",
    "        #Separamos los folds\n",
    "        train_X, validation_X = X.iloc[train_index, :], X.iloc[validation_index, :]\n",
    "        train_y, validation_y = y.iloc[train_index], y.iloc[validation_index]\n",
    "    \n",
    "        #Entrenamos el árbol\n",
    "        dt = DecisionTreeClassifier(max_depth = max_depth, criterion = criterion)\n",
    "        dt.fit(train_X, train_y)\n",
    "        \n",
    "        #Guardamos los resultados\n",
    "        accuracyValidation.append(np.round(accuracy_score(validation_y, dt.predict(validation_X)), round_decimals))\n",
    "        accuracyTrain.append(np.round(accuracy_score(train_y, dt.predict(train_X)), round_decimals))\n",
    "        \n",
    "        rocAucValidation.append(np.round(roc_auc_score(validation_y, dt.predict(validation_X)), round_decimals))\n",
    "        rocAucTrain.append(np.round(roc_auc_score(train_y, dt.predict(train_X)), round_decimals))\n",
    "                \n",
    "    return accuracyValidation, accuracyTrain, rocAucValidation, rocAucTrain\n",
    "\n",
    "def showResults(scores, label):\n",
    "    print(label)\n",
    "    print(\"Values: \", scores, \" Promedio = \", np.round(np.mean(scores), 3), \" Desvio = \", np.round(np.std(scores), 3),\"\\n\")\n",
    "    \n",
    "\n",
    "#2.1\n",
    "accuracyValidation, accuracyTrain, rocAucValidation, rocAucTrain = kfold()\n",
    "\n",
    "showResults(accuracyValidation, \"Accuracy: Conjunto de validación\")\n",
    "showResults(accuracyTrain, \"Accuracy: Conjunto de entrenamiento\")\n",
    "showResults(rocAucValidation, \"ROC AUC: Conjunto de validación\")\n",
    "showResults(rocAucTrain, \"ROC AUC: Conjunto de entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar árboles de decisión con las siguientes combinaciones. En todos los casos probar e informar Accuracy y ROC AUC para training y para validación con Gini y con Information Gain haciendo cross validation:\n",
    "    a. Altura máxima 3\n",
    "    b. Altura máxima 6\n",
    "    c. Sin límite de altura máxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áltura 3 Gini\n",
      "Acc Val: 0.798, Acc Train: 0.799, ROC AUC Val: 0.755, ROC AUC Train: 0.758\n",
      "\n",
      "Áltura 3 Information Gain\n",
      "Acc Val: 0.799, Acc Train: 0.800, ROC AUC Val: 0.757, ROC AUC Train: 0.758\n",
      "\n",
      "Áltura 6 Gini\n",
      "Acc Val: 0.804, Acc Train: 0.824, ROC AUC Val: 0.774, ROC AUC Train: 0.795\n",
      "\n",
      "Áltura 6 Information Gain\n",
      "Acc Val: 0.803, Acc Train: 0.817, ROC AUC Val: 0.766, ROC AUC Train: 0.781\n",
      "\n",
      "Sin límite de áltura Gini\n",
      "Acc Val: 0.784, Acc Train: 0.999, ROC AUC Val: 0.771, ROC AUC Train: 0.999\n",
      "\n",
      "Sin límite áltura Information Gain\n",
      "Acc Val: 0.774, Acc Train: 0.999, ROC AUC Val: 0.761, ROC AUC Train: 0.999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def showSummary(results, label):\n",
    "    print(label)\n",
    "    print('Acc Val: {:.3f}, Acc Train: {:.3f}, ROC AUC Val: {:.3f}, ROC AUC Train: {:.3f}\\n'.format(\n",
    "            np.mean(results[0]), np.mean(results[1]), np.mean(results[2]), np.mean(results[3])))\n",
    "\n",
    "#Altura 3 Gini\n",
    "showSummary(kfold(max_depth = 3, criterion = \"gini\"), \"Áltura 3 Gini\")\n",
    "showSummary(kfold(max_depth = 3, criterion = \"entropy\"), \"Áltura 3 Information Gain\")\n",
    "showSummary(kfold(max_depth = 6, criterion = \"gini\"), \"Áltura 6 Gini\")\n",
    "showSummary(kfold(max_depth = 6, criterion = \"entropy\"), \"Áltura 6 Information Gain\")\n",
    "showSummary(kfold(max_depth = None, criterion = \"gini\"), \"Sin límite de áltura Gini\")\n",
    "showSummary(kfold(max_depth = None, criterion = \"entropy\"), \"Sin límite áltura Information Gain\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
