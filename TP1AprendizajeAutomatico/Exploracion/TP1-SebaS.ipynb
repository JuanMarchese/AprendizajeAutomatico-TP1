{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando los Datos\n",
    "\n",
    "Datos del 01/02/2018 al 28/02/2018<br>\n",
    "Los datos Genre est√°n expresados en minutos vistos en el mes<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydotplus\n",
      "  Downloading https://files.pythonhosted.org/packages/60/bf/62567830b700d9f6930e9ab6831d6ba256f7b0b730acb37278b0ccdffacf/pydotplus-2.0.2.tar.gz (278kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\steye\\anaconda2\\lib\\site-packages (from pydotplus) (2.4.0)\n",
      "Building wheels for collected packages: pydotplus\n",
      "  Building wheel for pydotplus (setup.py): started\n",
      "  Building wheel for pydotplus (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\steye\\AppData\\Local\\pip\\Cache\\wheels\\35\\7b\\ab\\66fb7b2ac1f6df87475b09dc48e707b6e0de80a6d8444e3628\n",
      "Successfully built pydotplus\n",
      "Installing collected packages: pydotplus\n",
      "Successfully installed pydotplus-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'FullData.csv' does not exist: b'FullData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c2693b7c0c53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FullData.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date of birth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date of birth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'FullData.csv' does not exist: b'FullData.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"FullData.csv\")\n",
    "data['Date of birth']= pd.to_datetime(data['Date of birth'],format='%Y-%m-%d') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripcion de los valores:\n",
    "\n",
    "**Sex code:**<br>\n",
    "1 = Male<br>\n",
    "2 = Female<br>\n",
    "\n",
    "**Marital status**<br>\n",
    "1 = Married / living as married<br>\n",
    "2 = Single / divorced / separated <br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Household status**<br>\n",
    "1 = Neither Houseperson nor head of household <br>\n",
    "2 = Houseperson and NOT Head of Household <br>\n",
    "3 = Head of household and NOT Houseperson <br>\n",
    "4 = Both Houseperson and head of household <br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Working status**<br>\n",
    "1 = Working 30+ hours per week <br>\n",
    "2 = Working 8-29 hours per week <br>\n",
    "3 = Working less than 8 hours per week <br>\n",
    "4 = No paid work <br>\n",
    "5 = Full time education / under school age <br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Terminal age of education**<br>\n",
    "1 = 15 years and under <br>\n",
    "2 = 16-18 years <br>\n",
    "3 = 19 + years <br>\n",
    "4 = Still in education <br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Welsh Language code Welsh**<br>\n",
    "speaking fluency. Understand, speak write and read Welsh: <br>\n",
    "1 = Extremely well <br>\n",
    "2 = Quite well <br>\n",
    "3 = A little <br>\n",
    "4 = Can understand and speak some Welsh <br>\n",
    "5 = Can understand a little Welsh <br>\n",
    "9 = Not Welsh speaking/Not in Wales <br>\n",
    "0 = Unclassified <br>\n",
    "\n",
    "**Gaelic language code**<br>\n",
    "Gaelic speaking fluency. Understand, speak, write and read Gaelic. <br>\n",
    "1 = Extremely well <br>\n",
    "2 = Quite well <br>\n",
    "3 = A little <br>\n",
    "4 = Can understand and speak some Gaelic <br>\n",
    "5 = Can understand a little Gaelic <br>\n",
    "9 = Not Gaelic speaking/Not in Scotland<br> \n",
    "0 = Unclassified <br>\n",
    "\n",
    "**Dependency of Children**<br>\n",
    "1 = Parent/Guardian <br>\n",
    "2 = Dependent Child <br>\n",
    "3 = Neither <br>\n",
    "9 = Unclassified<br>\n",
    "\n",
    "**Lifestage (12 way classification)**<br>\n",
    "01 = Single, no children, with parents, aged 16-34 <br>\n",
    "02 = Single, no children, on own or with friends, aged 16-34 <br>\n",
    "03 = Couple, no children, aged 16-34 <br>\n",
    "04 = Single, no children, on own or with friends, aged 35-54 <br>\n",
    "05 = Couple, no children, aged 35-54 <br>\n",
    "06 = Single, no children, on own, aged 55+ <br>\n",
    "07 = Couple, no children, aged 55+ <br>\n",
    "08 = Either, youngest children 0-4, includes single parents <br>\n",
    "09 = Either, youngest children 5-9, includes single parents <br>\n",
    "10 = Either youngest children 10-15, includes single parents <br>\n",
    "11 = Either, Children 16+ none 0-15, aged 35+ <br>\n",
    "12 = Other <br>\n",
    "99 = Unclassified <br>\n",
    "\n",
    "**Ethnic Origin**<br>\n",
    "01 = White British<br>\n",
    "02 = Black ‚Äì Caribbean<br>\n",
    "03 = Black ‚Äì African<br>\n",
    "04 = Black ‚Äì other<br>\n",
    "05 = Asian ‚Äì Indian <br>\n",
    "06 = Asian ‚Äì Pakistani <br>\n",
    "07 = Asian ‚Äì Bangladeshi <br>\n",
    "08 = Chinese <br>\n",
    "09 = Any other background <br>\n",
    "10 = Other White <br>\n",
    "11 = Mixed ‚Äì White/Black Caribbean <br>\n",
    "12 = Mixed ‚Äì White/Black African <br>\n",
    "13 = Mixed ‚Äì White/Asian <br>\n",
    "14 = Other mixed background <br>\n",
    "15 = Other Asian background <br>\n",
    "16 = Don‚Äôt know <br>\n",
    "17 = Refused <br>\n",
    "99 = Unclassified<br> \n",
    "\n",
    "**Disability**<br>\n",
    "Normal daily activities limited by long-term disability/health problem: <br>\n",
    "001 = Yes, Limited a lot <br>\n",
    "002 = Yes, Limited a little <br>\n",
    "003 = No <br>\n",
    "999 = Unclassified <br>\n",
    "\n",
    "**Social Class**<br>\n",
    "AB - Higher & intermediate managerial, administrative, professional occupations<br>\n",
    "C1 - Supervisory, clerical & junior managerial, administrative, professional occupations<br>\n",
    "C2 - Skilled manual occupations<br>\n",
    "D/space - Semi-skilled & unskilled manual occupations<br>\n",
    "E/space - Unemployed and lowest grade occupations<br>\n",
    "blank is ‚ÄòUnclassified‚Äô<br>\n",
    "\n",
    "\n",
    "**Presence of Children**<br>\n",
    "1 = No children<br>\n",
    "2 = With children aged 0-3 years<br>\n",
    "3 = With children aged 4-9 years<br>\n",
    "4 = With children aged 0-3 and 4-9 years<br>\n",
    "5 = With children aged 10-15 years<br>\n",
    "6 = With children aged 0-3 and 10-15 years<br>\n",
    "7 = With children aged 4-9 and 10-15 years<br>\n",
    "8 = With children aged 0-3 and 4-9 and 10-15 years<br>\n",
    "9 = Unclassified<br>\n",
    "\n",
    "**Demographic cell**<br>\n",
    "Cell Lifestage Social Class<br>\n",
    "1 Pre-Family ABC1<br>\n",
    "2 Pre-Family C2DE<br>\n",
    "3 Young Family ABC1<br>\n",
    "4 Young Family C2DE<br>\n",
    "5 Older Family ABC1<br>\n",
    "6 Older Family C2DE<br>\n",
    "7 Post Family ABC1<br>\n",
    "8 Post Family C2DE<br>\n",
    "9 Inactive ABC1<br>\n",
    "10 Inactive C2DE<br>\n",
    "\n",
    "**Language Spoken at Home**<br>\n",
    "1 = Welsh<br>\n",
    "2 = English<br>\n",
    "3= Welsh & English equally<br>\n",
    "4 = Welsh and other language than English (equally)<br>\n",
    "5 = Other<br>\n",
    "9 = Undefined<br>\n",
    "\n",
    "**Welsh Speaking Home**\n",
    "1 = Wholly Welsh Speaking (all individuals 4+ are of Fluency 1, 2, 3 or 4)<br>\n",
    "2 = Partly Welsh Speaking (some individuals 4+ are of Fluency 1, 2, 3 or 4 with other being 5 or 6) 3 = Non Welsh Speaking<br>\n",
    "9 = Unclassified<br>\n",
    "\n",
    "**Broadband**<br>\n",
    "1 if the home has a broadband connection, else 2<br>\n",
    "\n",
    "**2014 Mosaic Classification**<br>\n",
    "\n",
    "|PVF Mosaic Code | Mosaic Type | Mosaic Type Definition | Mosaic Group | Mosaic Group Definition |\n",
    "|---|---|---|---|---|\n",
    "|001|1|World-Class Wealth|1|City Prosperity|\n",
    "|002|2|Uptown Elite|1|City Prosperity|\n",
    "|003|3|Penthouse Chic|1|City Prosperity|\n",
    "|004|4|Metro High-Flyers|1|City Prosperity|\n",
    "|005|5|Premium Fortunes|2|Prestige Position|\n",
    "|006|6|Diamond Days|2|Prestige Position|\n",
    "|007|7|Alpha Families|2|Prestige Position|\n",
    "|008|8|Bank of Mum and Dad|2|Prestige Position|\n",
    "|009|9|Empty-Nest Adventure|2|Prestige Position|\n",
    "|010|10|Wealthy Landowners|3|Country Living|\n",
    "|011|11|Rural Vogue|3|Country Living|\n",
    "|012|12|Scattered Homesteads|3|Country Living|\n",
    "|013|13|Village Retirement|3|Country Living|\n",
    "|014|14|Satellite Settlers|4|Rural Reality|\n",
    "|015|15|Local Focus|4|Rural Reality|\n",
    "|016|16|Outlying Seniors|4|Rural Reality|\n",
    "|017|17|Far-Flung Outposts|4|Rural Reality|\n",
    "|018|18|Legacy Elders|5|Senior Security|\n",
    "|019|19|Bungalow Haven|5|Senior Security|\n",
    "|020|20|Classic Grandparents|5|Senior Security|\n",
    "|021|21|Solo Retirees|5|Senior Security|\n",
    "|022|22|Boomerang Boarders|6|Suburban Stability|\n",
    "|023|23|Family Ties|6|Suburban Stability|\n",
    "|024|24|Fledgling Flee|6|Suburban Stability|\n",
    "|025|25|Dependable Me|6|Suburban Stability|\n",
    "|026|26|Cafes and Catchments|7|Domestic Success|\n",
    "|027|27|Thriving Independence|7|Domestic Success|\n",
    "|028|28|Modern Parents|7|Domestic Success|\n",
    "|029|29|Mid-Career Convention|7|Domestic Success|\n",
    "|030|30|Primary Ambitions|8|Aspiring Homemakers|\n",
    "|031|31|Affordable Fringe|8|Aspiring Homemakers|\n",
    "|032|32|First-Rung Futures|8|Aspiring Homemakers|\n",
    "|033|33|Contemporary Starts|8|Aspiring Homemakers|\n",
    "|034|34|New Foundations|8|Aspiring Homemakers|\n",
    "|035|35|Flying Solo|8|Aspiring Homemakers|\n",
    "|036|36|Solid Economy|9|Family Basics|\n",
    "|037|37|Budget Generations|9|Family Basics|\n",
    "|038|38|Childcare Squeeze|9|Family Basics|\n",
    "|039|39|Families with Needs|9|Family Basics|\n",
    "|040|40|Make Do & Move On|10|Transient Renters|\n",
    "|041|41|Disconnected Youth|10|Transient Renters|\n",
    "|042|42|Midwife Stopgap|10|Transient Renters|\n",
    "|043|43|Renting a Room|10|Transient Renters|\n",
    "|044|44|Inner City Stalwarts|11|Municipal Challenge|\n",
    "|045|45|Crowded Kaleidoscope|11|Municipal Challenge|\n",
    "|046|46|High Rise Residents|11|Municipal Challenge|\n",
    "|047|47|Streetwise Singles|11|Municipal Challenge|\n",
    "|048|48|Low Income Workers|11|Municipal Challenge|\n",
    "|049|49|Dependent Greys|12|Vintage Value|\n",
    "|050|50|Pocket Pensions|12|Vintage Value|\n",
    "|051|51|Aided Elderly|12|Vintage Value|\n",
    "|052|52|Estate Veterans|12|Vintage Value|\n",
    "|053|53|Seasoned Survivors|12|Vintage Value|\n",
    "|054|54|Down-to-Earth Owners|13|Modest Traditions|\n",
    "|055|55|Offspring Overspill|13|Modest Traditions|\n",
    "|056|56|Self Supporters|13|Modest Traditions|\n",
    "|057|57|Community Elders|14|Urban Cohesion|\n",
    "|058|58|Cultural Comforts|14|Urban Cohesion|\n",
    "|059|59|Asian Heritage|14|Urban Cohesion|\n",
    "|060|60|Ageing Access|14|Urban Cohesion|\n",
    "|061|61|Career Builders|15|Rental Hubs|\n",
    "|062|62|Central Pulse|15|Rental Hubs|\n",
    "|063|63|Flexible Workforce|15|Rental Hubs|\n",
    "|064|64|Bus-Route Renters|15|Rental Hubs|\n",
    "|065|65|Learners & Earners|15|Rental Hubs|\n",
    "|066|66|Student Scene|15|Rental Hubs|\n",
    "|099 |99|Unclassified/Suppressed postcodes|99|Unclassified/Suppressed postcodes|\n",
    "|992|992|Invalid / Missing postcode|992|Invalid / Missing postcode|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    print(i)\n",
    "    print()\n",
    "    print(data[i].describe())\n",
    "    print()\n",
    "    print(data[i].value_counts())\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚Üí Calcular la edad, seria una variable m√°s interesante para ver\n",
    "\n",
    "‚Üí Demographic cell 1 tiene igual distribucion  Presence of Children\n",
    "\n",
    "‚Üí Gaelic language code casi sin datos por fuera de c√≥digo 9\n",
    "\n",
    "‚Üí Dependency of Children todos en c√≥digo 9\n",
    "\n",
    "‚Üí No of Computers todos en c√≥digo 999\n",
    "\n",
    "‚Üí Genre Soaps?\n",
    "\n",
    "‚Üí Genre Religious la gran mayoria en 0\n",
    "\n",
    "‚Üí Genre PP Broadcast la gran mayoria en 0\n",
    "\n",
    "‚Üí Genre Education la gran mayoria en 0\n",
    "\n",
    "\n",
    "Para el TP vamos a seleccionar el atributo Clase Social y sexo (dise√±amos un √≠ndice combinado) como target. Se pueden plantear varias cuestiones alrededor de este atributo para intentar descubrir conocimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target']=[str(data['Sex code'][i])+'-'+str(data['Social Class'][i]) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cod=['1-AB','1-C1','1-C2','1-D ','1-E ','2-AB','2-C1','2-C2','2-D ','2-E ']\n",
    "val=[1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc=pd.DataFrame(cod,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Target']=[disc[disc[0]==data['target'][i]].index[0] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "hoy = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['edad']=[hoy.year-data['Date of birth'][i].year for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚Üí Calcular la edad, seria una variable m√°s interesante para ver\n",
    "\n",
    "‚Üí Demographic cell 1 tiene igual distribucion  Presence of Children\n",
    "\n",
    "‚Üí Gaelic language code casi sin datos por fuera de c√≥digo 9\n",
    "\n",
    "‚Üí Dependency of Children todos en c√≥digo 9\n",
    "\n",
    "‚Üí No of Computers todos en c√≥digo 999\n",
    "\n",
    "‚Üí Genre Soaps?\n",
    "\n",
    "‚Üí Genre Religious la gran mayoria en 0\n",
    "\n",
    "‚Üí Genre PP Broadcast la gran mayoria en 0\n",
    "\n",
    "‚Üí Genre Education la gran mayoria en 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modificamos las clasificaciones 9 99 999 0 definidas como nulas por np.na para que python las pueda identificar como tales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripcion de los valores:\n",
    "\n",
    "**Marital status**<br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Household status**<br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Working status**<br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Terminal age of education**<br>\n",
    "9 = Unclassified <br>\n",
    "\n",
    "**Dependency of Children**<br>\n",
    "9 = Unclassified<br>\n",
    "\n",
    "**Lifestage (12 way classification)**<br>\n",
    "99 = Unclassified <br>\n",
    "\n",
    "**Ethnic Origin**<br>\n",
    "99 = Unclassified<br> \n",
    "\n",
    "**Disability**<br>\n",
    "Normal daily activities limited by long-term disability/health problem: <br>\n",
    "999 = Unclassified <br>\n",
    "\n",
    "\n",
    "**Presence of Children**<br>\n",
    "9 = Unclassified<br>\n",
    "\n",
    "**Demographic cell**<br>\n",
    "Cell Lifestage Social Class<br>\n",
    "9 Inactive ABC1<br>\n",
    "10 Inactive C2DE<br>\n",
    "\n",
    "**Language Spoken at Home**<br>\n",
    "9 = Undefined<br>\n",
    "\n",
    "**Welsh Speaking Home**\n",
    "9 = Unclassified<br>\n",
    "\n",
    "**Broadband**<br>\n",
    "1 if the home has a broadband connection, else 2<br>\n",
    "\n",
    "**2014 Mosaic Classification**<br>\n",
    "\n",
    "|099 |99|Unclassified/Suppressed postcodes|99|Unclassified/Suppressed postcodes|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Marital status']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Marital status','Terminal age of education','Dependency of Children', 'Ethnic Origin', 'Presence of Children']\n",
    "# [9,9,9,99,9]\n",
    "\n",
    "data['Marital status']=[np.nan if data['Marital status'][i]==9 else data['Marital status'][i] for i in range(len(data))]\n",
    "data['Terminal age of education']=[np.nan if data['Terminal age of education'][i]==9 else data['Terminal age of education'][i] for i in range(len(data))]\n",
    "data['Ethnic Origin']=[np.nan if data['Ethnic Origin'][i]==99 else data['Ethnic Origin'][i] for i in range(len(data))]\n",
    "data['Presence of Children']=[np.nan if data['Presence of Children'][i]==9 else data['Presence of Children'][i] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos la cantidad de minutos totales\n",
    "data['min_totales']=[data[['Genre Drama',\n",
    "       'Genre Soaps', 'Genre Series Drama Generic', 'Genre Cinema Films',\n",
    "       'Genre TV Fils', 'Genre Entertainment', 'Genre Music', 'Genre Arts',\n",
    "       'Genre News/Weather', 'Genre Current Affairs', 'Genre Hobbies/Leisure',\n",
    "       'Genre Documentaries', 'Genre Religious', 'Genre Sport',\n",
    "       'Genre Children', 'Genre PP Broadcast', 'Genre Education',\n",
    "       'Genre Other Films']].iloc[i].sum() for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos la distribuci√≥n de los minutos vistos\n",
    "generos=['Genre Drama',\n",
    "       'Genre Soaps', 'Genre Series Drama Generic', 'Genre Cinema Films',\n",
    "       'Genre TV Fils', 'Genre Entertainment', 'Genre Music', 'Genre Arts',\n",
    "       'Genre News/Weather', 'Genre Current Affairs', 'Genre Hobbies/Leisure',\n",
    "       'Genre Documentaries', 'Genre Religious', 'Genre Sport',\n",
    "       'Genre Children', 'Genre PP Broadcast', 'Genre Education',\n",
    "       'Genre Other Films']\n",
    "for g in generos:\n",
    "        data[g+'- %']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in generos:\n",
    "        data[g+'- %']=data[g]/data['min_totales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Panelist ID', 'Sex code', 'Date of birth', 'Marital status',\n",
       "       'Household status', 'Working status', 'Terminal age of education',\n",
       "       'Welsh Language code', 'Gaelic language code', 'Dependency of Children',\n",
       "       'Life stage', 'Ethnic Origin', 'Disability', 'No of TV Sets',\n",
       "       'No of VCRs', 'No of PVRs', 'No of DVDs', 'No of People',\n",
       "       'Social Class', 'Presence of Children', 'Demographic cell 1',\n",
       "       'Language Spoken at Home', 'Welsh Speaking Home',\n",
       "       'Number of DVD Recorders', 'Number of DVD Players',\n",
       "       'Number of Sky PVRs', 'Number of other PVRs', 'Broadband',\n",
       "       'Mosaic Classification', 'No of Computers', 'Genre Drama',\n",
       "       'Genre Soaps', 'Genre Series Drama Generic', 'Genre Cinema Films',\n",
       "       'Genre TV Fils', 'Genre Entertainment', 'Genre Music', 'Genre Arts',\n",
       "       'Genre News/Weather', 'Genre Current Affairs', 'Genre Hobbies/Leisure',\n",
       "       'Genre Documentaries', 'Genre Religious', 'Genre Sport',\n",
       "       'Genre Children', 'Genre PP Broadcast', 'Genre Education',\n",
       "       'Genre Other Films', 'Genre Other', 'Genre Other.1', 'target', 'Target',\n",
       "       'edad', 'min_totales', 'Genre Drama- %', 'Genre Soaps- %',\n",
       "       'Genre Series Drama Generic- %', 'Genre Cinema Films- %',\n",
       "       'Genre TV Fils- %', 'Genre Entertainment- %', 'Genre Music- %',\n",
       "       'Genre Arts- %', 'Genre News/Weather- %', 'Genre Current Affairs- %',\n",
       "       'Genre Hobbies/Leisure- %', 'Genre Documentaries- %',\n",
       "       'Genre Religious- %', 'Genre Sport- %', 'Genre Children- %',\n",
       "       'Genre PP Broadcast- %', 'Genre Education- %', 'Genre Other Films- %'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos con que columnas vamos a trabajar\n",
    "# columnas con pocos datos y las que fueron usadas para armar el √≠ndice combinado se eliminan antes de empezar a hacer los an√°lisis de prepocesamiento\n",
    "# Panelist ID es √≠ndice y √∫nico, se elimina y nos quedamos con el √≠ndice del dataframe\n",
    "cols=['Marital status','Terminal age of education', 'Ethnic Origin', 'Presence of Children',\n",
    "      'Genre Drama','Genre Soaps', 'Genre Series Drama Generic', 'Genre Cinema Films',\n",
    "       'Genre TV Fils', 'Genre Entertainment', 'Genre Music', 'Genre Arts',\n",
    "       'Genre News/Weather', 'Genre Current Affairs', 'Genre Hobbies/Leisure',\n",
    "       'Genre Documentaries', 'Genre Religious', 'Genre Sport',\n",
    "       'Genre Children', 'Genre PP Broadcast', 'Genre Education',\n",
    "       'Genre Other Films','edad', 'min_totales', 'Genre Drama- %', 'Genre Soaps- %',\n",
    "       'Genre Series Drama Generic- %', 'Genre Cinema Films- %',\n",
    "       'Genre TV Fils- %', 'Genre Entertainment- %', 'Genre Music- %',\n",
    "       'Genre Arts- %', 'Genre News/Weather- %', 'Genre Current Affairs- %',\n",
    "       'Genre Hobbies/Leisure- %', 'Genre Documentaries- %',\n",
    "       'Genre Religious- %', 'Genre Sport- %', 'Genre Children- %',\n",
    "       'Genre PP Broadcast- %', 'Genre Education- %', 'Genre Other Films- %']\n",
    "y='Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se hace la separaci√≥n del datafreme inicial para no influir en test.\n",
    "# dejamos el 20% de la base para testear\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data[cols], data[y], train_size=0.8, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefinimos data como nuestro dataframe solomente con la informaci√≥n de train\n",
    "data_train=train_X.merge(train_y,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hasta este punto:\n",
    "‚Üí Definimos target. Indice combinado entre edad y clase social. La idea es poder predecir esto para poder dirigir campa√±as publicitarias o de promociones.\n",
    "\n",
    "‚Üí Agregamos las variables de edad y proporci√≥n de minutos por genero respecto al total de minutos.\n",
    "\n",
    "‚Üí Reemplazamos por nan los valores no clasificados.\n",
    "\n",
    "‚Üí Seleccionamos las variables que vamos a usar para definir nuestro target.\n",
    "\n",
    "‚Üí Hacemos la separaci√≥n test - train para no influir en las obervaciones de testeo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marital status\n",
      "0.0\n",
      "\n",
      "Terminal age of education\n",
      "0.0\n",
      "\n",
      "Ethnic Origin\n",
      "0.0\n",
      "\n",
      "Presence of Children\n",
      "0.0\n",
      "\n",
      "Genre Drama\n",
      "0.0\n",
      "\n",
      "Genre Soaps\n",
      "0.0\n",
      "\n",
      "Genre Series Drama Generic\n",
      "0.0\n",
      "\n",
      "Genre Cinema Films\n",
      "0.0\n",
      "\n",
      "Genre TV Fils\n",
      "0.0\n",
      "\n",
      "Genre Entertainment\n",
      "0.0\n",
      "\n",
      "Genre Music\n",
      "0.0\n",
      "\n",
      "Genre Arts\n",
      "0.0\n",
      "\n",
      "Genre News/Weather\n",
      "0.0\n",
      "\n",
      "Genre Current Affairs\n",
      "0.0\n",
      "\n",
      "Genre Hobbies/Leisure\n",
      "0.0\n",
      "\n",
      "Genre Documentaries\n",
      "0.0\n",
      "\n",
      "Genre Religious\n",
      "0.0\n",
      "\n",
      "Genre Sport\n",
      "0.0\n",
      "\n",
      "Genre Children\n",
      "0.0\n",
      "\n",
      "Genre PP Broadcast\n",
      "0.0\n",
      "\n",
      "Genre Education\n",
      "0.0\n",
      "\n",
      "Genre Other Films\n",
      "0.0\n",
      "\n",
      "edad\n",
      "0.0\n",
      "\n",
      "min_totales\n",
      "0.0\n",
      "\n",
      "Genre Drama- %\n",
      "0.0\n",
      "\n",
      "Genre Soaps- %\n",
      "0.0\n",
      "\n",
      "Genre Series Drama Generic- %\n",
      "0.0\n",
      "\n",
      "Genre Cinema Films- %\n",
      "0.0\n",
      "\n",
      "Genre TV Fils- %\n",
      "0.0\n",
      "\n",
      "Genre Entertainment- %\n",
      "0.0\n",
      "\n",
      "Genre Music- %\n",
      "0.0\n",
      "\n",
      "Genre Arts- %\n",
      "0.0\n",
      "\n",
      "Genre News/Weather- %\n",
      "0.0\n",
      "\n",
      "Genre Current Affairs- %\n",
      "0.0\n",
      "\n",
      "Genre Hobbies/Leisure- %\n",
      "0.0\n",
      "\n",
      "Genre Documentaries- %\n",
      "0.0\n",
      "\n",
      "Genre Religious- %\n",
      "0.0\n",
      "\n",
      "Genre Sport- %\n",
      "0.0\n",
      "\n",
      "Genre Children- %\n",
      "0.0\n",
      "\n",
      "Genre PP Broadcast- %\n",
      "0.0\n",
      "\n",
      "Genre Education- %\n",
      "0.0\n",
      "\n",
      "Genre Other Films- %\n",
      "0.0\n",
      "\n",
      "Target\n",
      "0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# completamos datos faltantes. Usamos el metodo mice (Multiple imputation by chained equations)\n",
    "for c in data_train.columns:\n",
    "    print(c)\n",
    "    print(len(data_train[data_train[c]==np.nan])/len(data_train))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fancyimpute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-05484c1c3316>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfancyimpute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfancyimpute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMICE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fancyimpute'"
     ]
    }
   ],
   "source": [
    "import fancyimpute  \n",
    "from sklearn.preprocessing import Imputer \n",
    "\n",
    "fancyimpute.MICE().complete(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer √°rbol\n",
    "\n",
    "cols=['Marital status', 'Terminal age of education', 'Ethnic Origin',\n",
    "       'Presence of Children', 'Genre Drama', 'Genre Soaps',\n",
    "       'Genre Series Drama Generic', 'Genre Cinema Films', 'Genre TV Fils',\n",
    "       'Genre Entertainment', 'Genre Music', 'Genre Arts',\n",
    "       'Genre News/Weather', 'Genre Current Affairs', 'Genre Hobbies/Leisure',\n",
    "       'Genre Documentaries', 'Genre Religious', 'Genre Sport',\n",
    "       'Genre Children', 'Genre PP Broadcast', 'Genre Education',\n",
    "       'Genre Other Films', 'edad', 'min_totales', 'Genre Drama- %',\n",
    "       'Genre Soaps- %', 'Genre Series Drama Generic- %',\n",
    "       'Genre Cinema Films- %', 'Genre TV Fils- %', 'Genre Entertainment- %',\n",
    "       'Genre Music- %', 'Genre Arts- %', 'Genre News/Weather- %',\n",
    "       'Genre Current Affairs- %', 'Genre Hobbies/Leisure- %',\n",
    "       'Genre Documentaries- %', 'Genre Religious- %', 'Genre Sport- %',\n",
    "       'Genre Children- %', 'Genre PP Broadcast- %', 'Genre Education- %',\n",
    "       'Genre Other Films- %']\n",
    "y='Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_X, data_test_X, data_train_y, data_test_y = train_test_split(data_train[cols], data_train[y], train_size=0.7, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-29468f876e08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdtree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "dtree=DecisionTreeClassifier(max_leaf_nodes=3)\n",
    "dtree.fit(data_train_X, data_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463624338624338\n",
      "0.7352899475400538\n"
     ]
    }
   ],
   "source": [
    "predictions=dtree.predict(test_X)\n",
    "predictions2=dtree.predict(train_X)\n",
    "acc=accuracy_score(test_y, predictions)\n",
    "acc2=accuracy_score(train_y, predictions2)\n",
    "\n",
    "print(acc)\n",
    "print(acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Sex code',\n",
    "       'Household status', 'Working status', 'Terminal age of education',\n",
    "       'Welsh Language code', 'Gaelic language code', 'Dependency of Children',\n",
    "       'Life stage', 'Ethnic Origin', 'Disability', 'No of TV Sets',\n",
    "       'No of VCRs', 'No of PVRs', 'No of DVDs', 'No of People',\n",
    "       'Presence of Children', 'Demographic cell 1',\n",
    "       'Language Spoken at Home', 'Welsh Speaking Home',\n",
    "       'Number of DVD Recorders', 'Number of DVD Players',\n",
    "       'Number of Sky PVRs', 'Number of other PVRs', 'Broadband',\n",
    "       'Mosaic Classification', 'No of Computers', 'Genre Drama',\n",
    "       'Genre Soaps', 'Genre Series Drama Generic', 'Genre Cinema Films',\n",
    "       'Genre TV Fils', 'Genre Entertainment', 'Genre Music', 'Genre Arts',\n",
    "       'Genre News/Weather', 'Genre Current Affairs', 'Genre Hobbies/Leisure',\n",
    "       'Genre Documentaries', 'Genre Religious', 'Genre Sport',\n",
    "       'Genre Children', 'Genre PP Broadcast', 'Genre Education',\n",
    "       'Genre Other Films', 'Genre Other', 'Genre Other.1']\n",
    "y='Marital status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data[cols], data[y], train_size=0.7, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=5, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree=DecisionTreeClassifier(max_leaf_nodes=5)\n",
    "dtree.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9153439153439153\n",
      "0.9211682971785056\n"
     ]
    }
   ],
   "source": [
    "predictions=dtree.predict(test_X)\n",
    "predictions2=dtree.predict(train_X)\n",
    "acc=accuracy_score(test_y, predictions)\n",
    "acc2=accuracy_score(train_y, predictions2)\n",
    "\n",
    "print(acc)\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Sex code','Marital status',\n",
    "       'Household status', 'Working status', \n",
    "       'Welsh Language code', 'Gaelic language code', 'Dependency of Children',\n",
    "       'Life stage', 'Ethnic Origin', 'Disability', 'No of TV Sets',\n",
    "       'No of VCRs', 'No of PVRs', 'No of DVDs', 'No of People',\n",
    "       'Presence of Children', 'Demographic cell 1',\n",
    "       'Language Spoken at Home', 'Welsh Speaking Home',\n",
    "       'Number of DVD Recorders', 'Number of DVD Players',\n",
    "       'Number of Sky PVRs', 'Number of other PVRs', 'Broadband',\n",
    "       'Mosaic Classification', 'No of Computers', 'Genre Drama',\n",
    "       'Genre Soaps', 'Genre Series Drama Generic', 'Genre Cinema Films',\n",
    "       'Genre TV Fils', 'Genre Entertainment', 'Genre Music', 'Genre Arts',\n",
    "       'Genre News/Weather', 'Genre Current Affairs', 'Genre Hobbies/Leisure',\n",
    "       'Genre Documentaries', 'Genre Religious', 'Genre Sport',\n",
    "       'Genre Children', 'Genre PP Broadcast', 'Genre Education',\n",
    "       'Genre Other Films', 'Genre Other', 'Genre Other.1']\n",
    "y='Terminal age of education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data[cols], data[y], train_size=0.7, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=5, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree=DecisionTreeClassifier(max_leaf_nodes=5)\n",
    "dtree.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5562169312169312\n",
      "0.5841485892528002\n"
     ]
    }
   ],
   "source": [
    "predictions=dtree.predict(test_X)\n",
    "predictions2=dtree.predict(train_X)\n",
    "acc=accuracy_score(test_y, predictions)\n",
    "acc2=accuracy_score(train_y, predictions2)\n",
    "\n",
    "print(acc)\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
